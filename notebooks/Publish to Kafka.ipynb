{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook allows to publish stuff onto a Kafka topic, for consumption by others, and then to read it back in. Will only work in Python 3\n",
    "\n",
    "To start Kafka, run \n",
    "`nohup ~/kafka/bin/kafka-server-start.sh ~/kafka/config/server.properties > ~/kafka/kafka.log 2>&1 &`\n",
    "\n",
    "Check its status with \n",
    "`tail ~/kafka/kafka.log`\n",
    "\n",
    "The command-line code for a Kafka listener is \n",
    "\n",
    "`~/kafka/bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test_topic_1 --from-beginning &`\n",
    "\n",
    "The command-line code for a command-line Kafka publisher is \n",
    "\n",
    "`echo \"Hello, World\" | ~/kafka/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test_topic_1 > /dev/null`\n",
    "\n",
    "(after installing Kafka according to https://www.digitalocean.com/community/tutorials/how-to-install-apache-kafka-on-ubuntu-14-04), but using kafka 0.9.0.1 instead of 8.2 as in that link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "ver=sys.version_info\n",
    "assert ver[0]>=3\n",
    "\n",
    "from rx import Observable, Observer\n",
    "from kafka import KafkaProducer, KafkaConsumer\n",
    "import io\n",
    "\n",
    "# install Avro using pip install avro-python3 NOT pip install avro\n",
    "import avro.schema \n",
    "import avro.io\n",
    "import json\n",
    "\n",
    "# import local stuff\n",
    "sys.path.append('../rx')\n",
    "from KafkaObserver import KafkaObserver\n",
    "from KafkaObservable import KafkaObservable\n",
    "topic='test_topic_1'\n",
    "avro_topic='avro_topic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence completed\n",
      "<KafkaObserver.KafkaObserver object at 0x7f6c8420f6d8>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<rx.disposables.anonymousdisposable.AnonymousDisposable at 0x7f6c8420fb38>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Send one record\n",
    "kprod=KafkaProducer()\n",
    "kprod.send(topic,bytes('test','utf-8'))\n",
    "\n",
    "# Send a sequence using the Observer wrapper\n",
    "kobs=KafkaObserver(kprod,topic)\n",
    "obs=Observable.from_iterable(range(6,20,2)) \n",
    "obs.map(lambda x: bytes(str(x), 'utf-8')).subscribe(kobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConsumerRecord(topic='test_topic_1', partition=0, offset=0, timestamp=None, timestamp_type=None, key=None, value=b'Hello, World', checksum=-1623774016, serialized_key_size=-1, serialized_value_size=12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read one record\n",
    "consumer1 = KafkaConsumer(topic, auto_offset_reset='earliest', consumer_timeout_ms=100) \n",
    "next(consumer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'value': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now use Avro\n",
    "\n",
    "schema = avro.schema.Parse(json.dumps({\n",
    "\"namespace\"    : \"example.avro\",\n",
    " \"type\": \"record\",\n",
    " \"name\": \"Test\",\n",
    " \"fields\": [ {\"name\": \"value\",  \"type\": [\"int\",\"null\"]} \n",
    " ]\n",
    "}))\n",
    "#schema = avro.schema.Parse(json.dumps(test_schema))\n",
    "\n",
    "def avroEncode(dict, schema):\n",
    "    writer = avro.io.DatumWriter(schema)\n",
    "    bytes_writer = io.BytesIO()\n",
    "    encoder = avro.io.BinaryEncoder(bytes_writer)\n",
    "    writer.write(dict, encoder)\n",
    "    return bytes_writer.getvalue()\n",
    "\n",
    "def avroDecode(msg,schema):\n",
    "    bytes_reader = io.BytesIO(msg)\n",
    "    decoder = avro.io.BinaryDecoder(bytes_reader)\n",
    "    reader = avro.io.DatumReader(schema)\n",
    "    return reader.read(decoder)\n",
    "                         \n",
    "    \n",
    "x=avroEncode({'value':1}, schema)\n",
    "avroDecode(x, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence completed\n",
      "<KafkaObserver.KafkaObserver object at 0x7f6c8412e668>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<rx.disposables.anonymousdisposable.AnonymousDisposable at 0x7f6c8412e908>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dump a bunch of records to Kafka. Next iteration should use timestamps so that things remain ordered\n",
    "kobs=KafkaObserver(KafkaProducer(),avro_topic)\n",
    "obs=Observable.from_iterable(range(6,20,2)).map(lambda x: {'value':x})\n",
    "obs.map( lambda x: avroEncode(x,schema) ).subscribe(kobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rx.disposables.anonymousdisposable.AnonymousDisposable at 0x7f6c84143320>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a Kafka Observable the pedestrian way\n",
    "consumer1 = KafkaConsumer(avro_topic,auto_offset_reset='earliest', enable_auto_commit=False,consumer_timeout_ms=100, value_deserializer=lambda x: avroDecode(x,schema))\n",
    "kafkaObservable=Observable.from_iterable(consumer1)\n",
    "kafkaObservable.subscribe(lambda x: print(x.value))\n",
    "\n",
    "# appears to run, but slowly, and doesn't print anything now though identical code did earlier?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rx.disposables.anonymousdisposable.AnonymousDisposable at 0x7f6c840d06d8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try to run my Observable wrapper\n",
    "from KafkaObservable import KafkaObservable\n",
    "myKafkaObservable=KafkaObservable(avro_topic,value_deserializer=lambda x: avroDecode(x,schema))\n",
    "myKafkaObservable.subscribe(lambda x: print(x.value))\n",
    "\n",
    "# appears to run, but slowly, and doesn't print anything now though identical code did earlier?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
